{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.nn.init as torch_init\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "                                    # same normalize as EfficientNet paper\n",
    "# cifar-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=load_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=load_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change fc output class numbers\n",
    "model._fc.out_features = 10\n",
    "\n",
    "# freezing convolutional weights\n",
    "#for param in model._blocks.parameters():\n",
    "#    param.requires_grad = False\n",
    "# not freeze convoluntional layers for this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and return accuracy\n",
    "def testing(model, testloader, criterion, computing_device):\n",
    "    # make sure model is in evaluation mode\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    test_batch_loss = []\n",
    "    for data in testloader:\n",
    "        data, target = data[0].to(computing_device), data[1].to(computing_device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        #test_batch_loss.append(loss)\n",
    "        val_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        val_correct += (preds == target).sum().item()\n",
    "    \n",
    "    val_loss = val_loss/len(testloader.dataset)\n",
    "    val_accuracy = 100.0 * val_correct/len(testloader.dataset)\n",
    "    \n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def training(model, optimizer, trainloader, criterion, computing_device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for data in trainloader:\n",
    "        data, target = data[0].to(computing_device), data[1].to(computing_device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        train_correct += (preds == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    train_accuracy = 100.0 * train_correct/len(trainloader.dataset)\n",
    "    \n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 : train loss 0.029098667112886906, train accuracy 77.982\n",
      "Epoch0 : test loss 0.007227938933670521, test accuracy 92.83\n",
      "Epoch1 : train loss 0.007433852560818195, train accuracy 92.156\n",
      "Epoch1 : test loss 0.005735882423818111, test accuracy 94.24\n",
      "Epoch2 : train loss 0.005221331487298012, train accuracy 94.4\n",
      "Epoch2 : test loss 0.004695287980139256, test accuracy 95.41\n",
      "Epoch3 : train loss 0.0038787417989969253, train accuracy 95.814\n",
      "Epoch3 : test loss 0.003956038857996464, test accuracy 96.01\n",
      "Epoch4 : train loss 0.003081741962134838, train accuracy 96.728\n",
      "Epoch4 : test loss 0.0036610833182930944, test accuracy 96.4\n",
      "Epoch5 : train loss 0.002483963512778282, train accuracy 97.34\n",
      "Epoch5 : test loss 0.003542520788311958, test accuracy 96.42\n",
      "Epoch6 : train loss 0.002105522178411484, train accuracy 97.746\n",
      "Epoch6 : test loss 0.003467254935204983, test accuracy 96.58\n",
      "Epoch7 : train loss 0.0017796184101700782, train accuracy 98.066\n",
      "Epoch7 : test loss 0.0033724164709448812, test accuracy 96.82\n",
      "Epoch8 : train loss 0.0015440290334820747, train accuracy 98.374\n",
      "Epoch8 : test loss 0.003375960147380829, test accuracy 96.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch = 30\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "# define optimizer and loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# bring model to computing device\n",
    "model = model.to(computing_device)\n",
    "best_model_weights = copy.deepcopy(model.state_dict()) \n",
    "\n",
    "# start training with early stopping\n",
    "for epoch in range(n_epoch):\n",
    "    loss,acc = training(model, optimizer, trainloader, criterion, computing_device)\n",
    "    train_loss.append(loss)\n",
    "    train_acc.append(acc)\n",
    "    print(\"Epoch\" + str(epoch) + \" : train loss \" + str(loss) + \", train accuracy \" + str(acc))\n",
    "    \n",
    "    loss,acc = testing(model, testloader, criterion, computing_device)\n",
    "    test_loss.append(loss)\n",
    "    test_acc.append(acc)\n",
    "    print(\"Epoch\" + str(epoch) + \" : test loss \" + str(loss) + \", test accuracy \" + str(acc))\n",
    "\n",
    "    \n",
    "    ##################early stop####################\n",
    "    # early stop if validation loss increased\n",
    "    if(epoch > 5):\n",
    "        before = test_loss[-2]\n",
    "        after = test_loss[-1]\n",
    "        if (before < after and test_acc[-2] > test_acc[-1]):\n",
    "            break\n",
    "        else:\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "model.load_state_dict(best_model_weights)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "torch.save(model.state_dict(), 'model/efficient_net_b1_cifar10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "np.save('result/train_loss_b1_basseline.npy', train_loss)\n",
    "np.save('result/train_acc_b1_basseline.npy', train_acc)\n",
    "np.save('result/test_loss_b1_basseline.npy', test_loss)\n",
    "np.save('result/test_acc_b1_basseline.npy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adv testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
